{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\p\\BigARTM\\Python\\artm\\master_component.py:643: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "C:\\p\\BigARTM\\Python\\artm\\master_component.py:753: DeprecationWarning: invalid escape sequence \\d\n",
      "  \"\"\"\n",
      "C:\\p\\BigARTM\\Python\\artm\\master_component.py:826: DeprecationWarning: 'async' and 'await' will become reserved keywords in Python 3.7\n",
      "  apply_weight=None, decay_weight=None, async=None):\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import artm\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work environment setup - one-time actions\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE STOP-WORDS DATASET\n",
    "def make_stop_words_dataset():\n",
    "    stemmer = SnowballStemmer('russian')\n",
    "    stop_words= nltk.corpus.stopwords.words('russian')\n",
    "    stop_words = list(map(lambda x: stemmer.stem(x), stop_words))\n",
    "    pd.DataFrame(stop_words).to_csv('stop-words-russian-nltk.csv', index=False, header=['stop-word'])\n",
    "\n",
    "\n",
    "make_stop_words_dataset()\n",
    "\n",
    "# stop_word=\" \"\n",
    "# for i in stop_words:\n",
    "#         stop_word=  stop_word+\" \"+i\n",
    "# print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATA PREPARATION\n",
    "# load raw data\n",
    "def load_data():\n",
    "    NROWS = None # 1000\n",
    "    df = pd.read_csv(\n",
    "        'vk.csv',\n",
    "        nrows=NROWS, \n",
    "        low_memory=False, \n",
    "        dtype={'question': 'str',\n",
    "               'answer':'str'})\n",
    "    return df\n",
    "\n",
    "\n",
    "# stemming\n",
    "def stemming(df):\n",
    "    df['question_stem'] = df['question'].apply(lambda x: ' '.join([stemmer.stem(w) for w in str(x).split()]))\n",
    "    df['answer_stem'] = df['answer'].apply(lambda x: ' '.join([stemmer.stem(w) for w in str(x).split()]))\n",
    "    # df[['question_stem','answer_stem']]\n",
    "    # df.to_csv('vk-stemmed.csv', index=False, header=True)\n",
    "\n",
    "    # remove punctuation & stop-words\n",
    "    stop_words = list(pd.read_csv('stop-words-russian-nltk.csv')['stop-word'])\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    words = nltk.word_tokenize(s)\n",
    "    words = [w for w in words if w not in stop_words]  # remove stop-words\n",
    "    words = [w for w in words if w.isalpha() and len(w)>1]  # remove numbers and single-char\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def data_preparation():\n",
    "    df = load_data()\n",
    "    stemming(df)\n",
    "    \n",
    "    df['question_clean'] = df['question_stem'].apply(lambda x: clean_text(x))\n",
    "    df['answer_clean'] = df['answer_stem'].apply(lambda x: clean_text(x))\n",
    "    df.to_csv('vk-cleaned.csv', index=False, header=True, columns=['question_clean','answer_clean'])\n",
    "\n",
    "\n",
    "data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    кредитн карт моментум расплачива зарубежн инте...\n",
       "Name: question_clean, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('vk-cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vw(text, label ):\n",
    "    global line_number\n",
    "    line_number += 1\n",
    "    return label + str(line_number) + ' ' + str(text)\n",
    "\n",
    "line_number = 0\n",
    "df['question_vw'] = df['question_clean'].apply(lambda x: text2vw(x, 'q'))\n",
    "\n",
    "line_number = 0\n",
    "df['answer_vw'] = df['answer_clean'].apply(lambda x: text2vw(x, 'a'))\n",
    "\n",
    "df[['question_vw', 'answer_vw']].to_csv('vk.vw', index=False, header=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ARTM batches & dictionary - one-time action\n",
    "batch_vectorizer = artm.BatchVectorizer(\n",
    "    data_path = 'vk.vw',\n",
    "    data_format='vowpal_wabbit',\n",
    "    target_folder='artm')\n",
    "\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.gather(data_path='artm')\n",
    "dictionary.save(dictionary_path='artm/dictionary')\n",
    "dictionary.save_text(dictionary_path='artm/dictionary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.load(dictionary_path='artm/dictionary.dict')\n",
    "model = artm.ARTM(num_topics=200, dictionary=dictionary, cache_theta=True)\n",
    "model.scores.add(artm.PerplexityScore(name='perplexity_score', dictionary=dictionary))\n",
    "model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score'))\n",
    "model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
    "model.scores.add(artm.TopTokensScore(name='top_tokens_score'))\n",
    "model.num_document_passes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)\n",
    "#model.score_tracker['perplexity_score'].last_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71341.4765625, 1401.7366943359375, 1058.3416748046875, 695.7772216796875, 489.915771484375, 396.8744201660156, 345.58721923828125, 311.3427734375, 287.19354248046875, 270.26739501953125, 257.99127197265625, 248.8828125, 242.0885467529297, 236.82847595214844, 232.6487579345703, 229.35733032226562, 226.8046112060547, 224.83163452148438, 223.2830047607422, 222.04257202148438, 221.00869750976562, 220.13475036621094, 219.37721252441406, 218.72799682617188, 218.174072265625]\n",
      "\n",
      "[0.0, 1.1741341950255446e-05, 0.0004088670539204031, 0.028938917443156242, 0.15169109404087067, 0.3843666911125183, 0.5906117558479309, 0.7183569669723511, 0.7896561622619629, 0.8311086297035217, 0.8579050898551941, 0.8772653341293335, 0.8925049304962158, 0.9049971103668213, 0.9155004620552063, 0.9244206547737122, 0.9321203231811523, 0.9388247132301331, 0.9446538686752319, 0.9496938586235046, 0.9541117548942566, 0.9579960107803345, 0.9613600373268127, 0.9643058776855469, 0.9669113159179688]\n",
      "\n",
      "[0.0, 8.72448083555355e-07, 2.8167609343654476e-05, 4.898172846878879e-05, 0.00010195178765570745, 0.00023543635325040668, 0.0004896926693618298, 0.0011121220886707306, 0.0024178028106689453, 0.004784131422638893, 0.008369394578039646, 0.01331405621021986, 0.020157912746071815, 0.029315875843167305, 0.04093090072274208, 0.05527631565928459, 0.07317658513784409, 0.09397661685943604, 0.11575566232204437, 0.13845090568065643, 0.15995700657367706, 0.1793689727783203, 0.19745294749736786, 0.2159847468137741, 0.2336503267288208]\n"
     ]
    }
   ],
   "source": [
    "print(model.score_tracker['perplexity_score'].value)      # .last_value\n",
    "print()\n",
    "print(model.score_tracker['sparsity_phi_score'].value)    # .last_value\n",
    "print()\n",
    "print(model.score_tracker['sparsity_theta_score'].value)  # .last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cache_theta == False. Set ARTM.cache_theta = True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-773059a5d784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_theta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\p\\BigARTM\\Python\\artm\\artm_model.py\u001b[0m in \u001b[0;36mget_theta\u001b[1;34m(self, topic_names)\u001b[0m\n\u001b[0;32m    799\u001b[0m         \"\"\"\n\u001b[0;32m    800\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_theta\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cache_theta == False. Set ARTM.cache_theta = True'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model does not exist yet. Use ARTM.initialize()/ARTM.fit_*()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cache_theta == False. Set ARTM.cache_theta = True"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_ngrams(s):\n",
    "#     tokens = nltk.word_tokenize(s)\n",
    "    \n",
    "\n",
    "# df['question_ngram'] = dfp['question_stem'].apply(\n",
    "#     lambda x: process_ngrams(x)\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
